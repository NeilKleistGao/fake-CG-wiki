## 向量空间
向量空间是指一组向量所组成的空间，这些向量需要满足条件：向量的任意线性组合的结果依然在该向量空间中。也就是说向量的线性组合应该是封闭的。

我们还可以给出一个更正式的定义：

+ 向量的加法满足交换律： $\vec u + \vec v = \vec v + \vec u$
+ 向量加法满足结合律： $\vec u + (\vec v + \vec w) = \vec u + \vec v + \vec w$
+ 存在一个零向量，使得 $\vec u + \vec 0 = \vec u$
+ 每一个向量都存在其逆向量，使得 $\vec u + (-\vec u) = \vec 0$
+ 标量乘法满足结合律： $\alpha(\beta \vec u) = (\alpha \beta) \vec u$
+ 标量乘法存在一个单位元，使得 $1\vec u = \vec u$
+ 标量乘法满足分配律： $(\alpha + \beta)\vec u = \alpha \vec u + \beta \vec u, \alpha(\vec u + \vec v) = \alpha \vec u + \alpha \vec v$

最常见的向量空间为 $R^n$ ，即我们常见的n维空间，比如三维空间或者二维平面，我们很容易可以验证它们是向量空间。

除了这些“巨大”的向量空间外，我们还对潜在的小的向量空间感兴趣。例如：三维空间中的某个二维平面是不是一个向量空间？
这些 $R^n$ 空间中更小的空间被称为子空间。当然， $R^n$ 也是自己的子空间，除此以外的子空间被称为真子空间。

## 子空间
### 列空间
我们再来回顾一下方程组 $Ax = b$ 。从**列向量的线性组合**的视角来看，这个方程组是否有解，取决于 $\vec b$ 能否由矩阵 $A$ 中的列向量线性组合得出。
我们不妨认为矩阵 $A$ 中的列向量构成了一个向量空间，即矩阵的列空间，记作 $C(A)$ 。而此时方程组是否有解就取决于 $\vec b$ 是否在这个列空间中。

我们以下面这个矩阵为例：

$$
\begin{bmatrix}
    1 & 2 \\
    2 & 1 \\
    1 & 1
\end{bmatrix}
$$

这个矩阵的行数为3,所以这些列向量是 $R^3$ 中的向量。但是由这个矩阵所表示的列空间却不是 $R^3$ ，我们很容易可以从 $R^3$ 中找出一个向量，使得 $Ax = b$ 无解。

事实上，这个列空间实质是 $R^3$ 中一个经过原点的平面。但它和一个普通的二维平面不同：二维平面上的点只有两维坐标，而此时 $C(A)$ 中的向量有三维。

如果这个矩阵恰好是一个 $3 \times 3$ 的矩阵，且矩阵恰好有逆，那么这个列空间就是 $R^3$ 本身，因为对于任意的 $\vec b$ ，我们都能通过求逆的方式找到对应的解。

### 零空间
考虑 $Ax = b$ 的一个特殊形式： $Ax = 0$ 。此时我们不再考虑 $A$ 中的向量，而是考虑这个方程的解 $x$ ：所有的 $x$ 放在一起，这些向量能否构成一个向量空间？

答案是：可以！首先，零向量一定在这个空间中；其次，对于任意满足方程的两个向量 $\vec u, \vec v$ ，我们都可以有 $A(\vec u + \vec v) = A\vec u + A\vec v = 0$，这样就满足了封闭的条件。这个空间我们称之为矩阵的零空间，记作 $N(A)$ 。 

我们以下面这个矩阵为例：

$$
\begin{bmatrix}
    1 & 2 & 3 \\
    2 & 4 & 6
\end{bmatrix}
$$

我们很容易可以写出一些解来：

$$
\begin{bmatrix}
    0 \\ 0 \\ 0
\end{bmatrix},
\begin{bmatrix}
    2 \\ -1 \\ 0
\end{bmatrix},
\begin{bmatrix}
    1 \\ 1 \\ -1
\end{bmatrix},
\dots
$$

不难发现，这些向量最终也可以表示成 $R^3$ 中的某个二维平面。如果这个矩阵恰好是一个 $3 \times 3$ 的矩阵，且矩阵恰好有逆，那么此时矩阵的零空间中只包含零向量。
这样的零空间也是最小的子空间。

## 参考资料
+ [麻省理工公开课：线性代数](https://open.163.com/newview/movie/courseintro?newurl=M6V0BQC4M)
+ [向量空间- 维基百科，自由的百科全书](https://zh.wikipedia.org/wiki/%E5%90%91%E9%87%8F%E7%A9%BA%E9%97%B4)